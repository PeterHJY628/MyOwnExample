{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9154b44de869422984f016271d737899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdbc1c810b454b60aa9aebe5334b94fd",
              "IPY_MODEL_e667d2b753f240d98025eb5164991fd8",
              "IPY_MODEL_d71750d5435b4231bf9dc0ac2f201140"
            ],
            "layout": "IPY_MODEL_a4f8c5b205f842ccbc1f0c43e72879a8"
          }
        },
        "fdbc1c810b454b60aa9aebe5334b94fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf06c12f856497faabaaf94b72d459a",
            "placeholder": "​",
            "style": "IPY_MODEL_55b61c880aef482db5032c5776123fef",
            "value": "config.json: 100%"
          }
        },
        "e667d2b753f240d98025eb5164991fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de51812fadc0448fab49c28c03a0fa6c",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e698b8642f4b5c8380e522784fd763",
            "value": 665
          }
        },
        "d71750d5435b4231bf9dc0ac2f201140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e2ffe9c9ec44da98d921b0a6887eca",
            "placeholder": "​",
            "style": "IPY_MODEL_ee0de33e087647f78b81249351c3d94c",
            "value": " 665/665 [00:00&lt;00:00, 49.0kB/s]"
          }
        },
        "a4f8c5b205f842ccbc1f0c43e72879a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf06c12f856497faabaaf94b72d459a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b61c880aef482db5032c5776123fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de51812fadc0448fab49c28c03a0fa6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e698b8642f4b5c8380e522784fd763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06e2ffe9c9ec44da98d921b0a6887eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0de33e087647f78b81249351c3d94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70f7d7da2eb74e8cac20724b1b2983ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbb458fa8a3445f6bae05b096bf66b76",
              "IPY_MODEL_d59c8388eee54bb290c9be6731ab15e1",
              "IPY_MODEL_f82d6fff36334509ac01e617423effb1"
            ],
            "layout": "IPY_MODEL_7f53c1cdea2142149152430abc898577"
          }
        },
        "dbb458fa8a3445f6bae05b096bf66b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8270b1aa38e45ccb46a23c2426b9127",
            "placeholder": "​",
            "style": "IPY_MODEL_aad3eb1185954410af5f704a004e3887",
            "value": "model.safetensors: 100%"
          }
        },
        "d59c8388eee54bb290c9be6731ab15e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d977358040e84abd821d12ea1289ba68",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9ca6d9db2524cc89fcb091c37cdbe6f",
            "value": 548105171
          }
        },
        "f82d6fff36334509ac01e617423effb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6560c6cf13443849fad47956d23303d",
            "placeholder": "​",
            "style": "IPY_MODEL_dfd596e6f59f4891a3acb9c9c0537d57",
            "value": " 548M/548M [00:02&lt;00:00, 224MB/s]"
          }
        },
        "7f53c1cdea2142149152430abc898577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8270b1aa38e45ccb46a23c2426b9127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad3eb1185954410af5f704a004e3887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d977358040e84abd821d12ea1289ba68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ca6d9db2524cc89fcb091c37cdbe6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6560c6cf13443849fad47956d23303d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfd596e6f59f4891a3acb9c9c0537d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9db1865dc6b494a971286ce21358191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61a4d68e0f7d41cdae9e1844e26cb933",
              "IPY_MODEL_4d48830404b44732aaa99ab96fbc1435",
              "IPY_MODEL_06226e98c5754a22942498f2c94824e6"
            ],
            "layout": "IPY_MODEL_14d9d0effd9047ed875f7d3aa9f04840"
          }
        },
        "61a4d68e0f7d41cdae9e1844e26cb933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5b951ba18384a7ab0cf8e9cd382a182",
            "placeholder": "​",
            "style": "IPY_MODEL_9a6befe4f3604d2b9a09fe3a7e89c48c",
            "value": "generation_config.json: 100%"
          }
        },
        "4d48830404b44732aaa99ab96fbc1435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18dc2ab1c7e9442a8d31d909ab193556",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b48f6a70bc74208a50670c82c0f9812",
            "value": 124
          }
        },
        "06226e98c5754a22942498f2c94824e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bcd8f856e6743cc856263c9bc7999d0",
            "placeholder": "​",
            "style": "IPY_MODEL_65257199b62349999bf41b869f27e562",
            "value": " 124/124 [00:00&lt;00:00, 5.87kB/s]"
          }
        },
        "14d9d0effd9047ed875f7d3aa9f04840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b951ba18384a7ab0cf8e9cd382a182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6befe4f3604d2b9a09fe3a7e89c48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18dc2ab1c7e9442a8d31d909ab193556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b48f6a70bc74208a50670c82c0f9812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bcd8f856e6743cc856263c9bc7999d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65257199b62349999bf41b869f27e562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterHJY628/MyOwnExample/blob/main/%E2%80%9CLoRA_PitVQA_Sentence_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e3HXmQrS6QV",
        "outputId": "c3ee861b-27a0-4496-c94a-09190a731ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PitVQA'...\n",
            "remote: Enumerating objects: 401, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
            "remote: Total 401 (delta 74), reused 0 (delta 0), pack-reused 262 (from 1)\u001b[K\n",
            "Receiving objects: 100% (401/401), 14.44 MiB | 13.96 MiB/s, done.\n",
            "Resolving deltas: 100% (199/199), done.\n",
            "/content/PitVQA/datasets\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1FoAEY_u0PTAlrscjEifi2om15A83wL78\n",
            "From (redirected): https://drive.google.com/uc?id=1FoAEY_u0PTAlrscjEifi2om15A83wL78&confirm=t&uuid=b053a0d9-5ab6-4f2a-95ce-303c49bb2891\n",
            "To: /content/PitVQA/datasets/EndoVis-18-VQA.zip\n",
            "100% 2.71G/2.71G [00:47<00:00, 57.3MB/s]\n",
            "/content/PitVQA\n"
          ]
        }
      ],
      "source": [
        "#Download code\n",
        "!git clone https://github.com/HRL-Mike/PitVQA.git\n",
        "\n",
        "#Download Dataset\n",
        "!mkdir /content/PitVQA/datasets\n",
        "%cd /content/PitVQA/datasets\n",
        "!gdown --id 1FoAEY_u0PTAlrscjEifi2om15A83wL78\n",
        "\n",
        "# Unzipping the VQA EndoVis18 Dataset\n",
        "!unzip -q EndoVis-18-VQA.zip\n",
        "%cd /content/PitVQA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm==0.9.12 fairscale==0.4.13 scikit-learn==1.3.2\n",
        "#instal python package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOkwHQeZTOZi",
        "outputId": "8fd958f9-cf06-4302-eaae-8ff3a5077ea7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/60.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/266.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install peft"
      ],
      "metadata": {
        "id": "JJKP0OvRjwmL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import GPT2Model\n",
        "\n",
        "gpt = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "gpt"
      ],
      "metadata": {
        "id": "VUSOHj4Kf5Rm",
        "outputId": "4592d2d6-f6a0-4160-de78-be261a513663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708,
          "referenced_widgets": [
            "9154b44de869422984f016271d737899",
            "fdbc1c810b454b60aa9aebe5334b94fd",
            "e667d2b753f240d98025eb5164991fd8",
            "d71750d5435b4231bf9dc0ac2f201140",
            "a4f8c5b205f842ccbc1f0c43e72879a8",
            "0bf06c12f856497faabaaf94b72d459a",
            "55b61c880aef482db5032c5776123fef",
            "de51812fadc0448fab49c28c03a0fa6c",
            "34e698b8642f4b5c8380e522784fd763",
            "06e2ffe9c9ec44da98d921b0a6887eca",
            "ee0de33e087647f78b81249351c3d94c",
            "70f7d7da2eb74e8cac20724b1b2983ce",
            "dbb458fa8a3445f6bae05b096bf66b76",
            "d59c8388eee54bb290c9be6731ab15e1",
            "f82d6fff36334509ac01e617423effb1",
            "7f53c1cdea2142149152430abc898577",
            "d8270b1aa38e45ccb46a23c2426b9127",
            "aad3eb1185954410af5f704a004e3887",
            "d977358040e84abd821d12ea1289ba68",
            "e9ca6d9db2524cc89fcb091c37cdbe6f",
            "f6560c6cf13443849fad47956d23303d",
            "dfd596e6f59f4891a3acb9c9c0537d57",
            "b9db1865dc6b494a971286ce21358191",
            "61a4d68e0f7d41cdae9e1844e26cb933",
            "4d48830404b44732aaa99ab96fbc1435",
            "06226e98c5754a22942498f2c94824e6",
            "14d9d0effd9047ed875f7d3aa9f04840",
            "e5b951ba18384a7ab0cf8e9cd382a182",
            "9a6befe4f3604d2b9a09fe3a7e89c48c",
            "18dc2ab1c7e9442a8d31d909ab193556",
            "2b48f6a70bc74208a50670c82c0f9812",
            "1bcd8f856e6743cc856263c9bc7999d0",
            "65257199b62349999bf41b869f27e562"
          ]
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9154b44de869422984f016271d737899"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70f7d7da2eb74e8cac20724b1b2983ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9db1865dc6b494a971286ce21358191"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM #transformers is the class lib from hugging face\n",
        "from peft import LoraModel, LoraConfig, get_peft_model #Parameter-Efficient Fine-Tuning class\n",
        "\n",
        "config = LoraConfig(\n",
        "    # task_type=\"CAUSAL_LM\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    # target_modules=[\"q\", \"v\"],\n",
        "    # target_modules=[\"wte\"],\n",
        "    target_modules=[\"c_attn\"],#self attention module\n",
        "    # target_modules=[\"wte\"],\n",
        "    lora_dropout=0.01,\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(gpt, config)#combine oretrained model with LoRA config\n",
        "lora_model"
      ],
      "metadata": {
        "id": "A0DQPnOzm4vG",
        "outputId": "b4d8ad07-879e-413d-dd9e-e4300827102f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): GPT2LMHeadModel(\n",
              "      (transformer): GPT2Model(\n",
              "        (wte): Embedding(50257, 768)\n",
              "        (wpe): Embedding(1024, 768)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (h): ModuleList(\n",
              "          (0-11): 12 x GPT2Block(\n",
              "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): GPT2SdpaAttention(\n",
              "              (c_attn): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=2304, nx=768)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.01, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (c_proj): Conv1D(nf=768, nx=768)\n",
              "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): GPT2MLP(\n",
              "              (c_fc): Conv1D(nf=3072, nx=768)\n",
              "              (c_proj): Conv1D(nf=768, nx=3072)\n",
              "              (act): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader"
      ],
      "metadata": {
        "id": "zn1LPGY3UPnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "from PIL import Image#load and process image\n",
        "from torch.utils.data import Dataset# PyTorch 数据集类的基类，用于创建自定义数据集。\n",
        "import torchvision.transforms as transforms#提供了一系列图像预处理和数据增强工具，例如图像缩放、裁剪、归一化等。\n",
        "from torch.utils.data import DataLoader#PyTorch 的数据加载器，可以高效地加载批量数据，支持多线程。\n",
        "from pathlib import Path#用于跨平台操作文件路径，更现代和灵活。\n",
        "from torchvision.transforms.functional import InterpolationMode#提供的插值模式，用于图像缩放时的插值方法，例如最近邻插值、双线性插值等。\n",
        "\n",
        "class EndoVis18VQAGPTGen(Dataset):\n",
        "    def __init__(self, seq, folder_head, folder_tail):\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),  # input image size\n",
        "            transforms.ToTensor(),#将图像转换为 PyTorch 张量，归一化到 [0, 1] 范围\n",
        "        ])\n",
        "\n",
        "        # files, question and answers\n",
        "        filenames = []\n",
        "        for curr_seq in seq:\n",
        "            filenames = filenames + glob.glob(folder_head + str(curr_seq) + folder_tail)\n",
        "        self.vqas = []\n",
        "        for file in filenames:\n",
        "            file_data = open(file, \"r\")\n",
        "            lines = [line.strip(\"\\n\") for line in file_data if line != \"\\n\"]\n",
        "            file_data.close()\n",
        "            for line in lines:\n",
        "                self.vqas.append([file, line])\n",
        "        print('Total files: %d | Total question: %.d' % (len(filenames), len(self.vqas)))\n",
        "\n",
        "        # Labels\n",
        "        self.labels = ['kidney',\n",
        "                'Idle', 'Grasping', 'Retraction', 'Tissue_Manipulation',\n",
        "                'Tool_Manipulation', 'Cutting', 'Cauterization', 'Suction',\n",
        "                'Looping', 'Suturing', 'Clipping', 'Staple', 'Ultrasound_Sensing',\n",
        "                'left-top', 'right-top', 'left-bottom', 'right-bottom'] #18 labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vqas)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        qa_full_path = Path(self.vqas[idx][0])\n",
        "        seq_path = qa_full_path.parents[2]\n",
        "        file_name = self.vqas[idx][0].split('/')[-1]  # / in linux and \\\\ in windows\n",
        "\n",
        "        # img\n",
        "        img_loc = os.path.join(seq_path, 'left_fr', file_name.split('_')[0] + '.png')\n",
        "        raw_image = Image.open(img_loc).convert('RGB')\n",
        "        img = self.transform(raw_image)#self.transform：对图像应用预处理，例如调整大小、转换为张量等。\n",
        "\n",
        "        # question and answer\n",
        "        question, answer = self.vqas[idx][1].split('|')\n",
        "\n",
        "        return img_loc, img, question, answer"
      ],
      "metadata": {
        "id": "-6kiE739TSFP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "j9ySe-NcULLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import ViTModel, BlipConfig, BlipTextModel\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#LoRA module class,用于调整自注意力机制中的 qkv 权重。\n",
        "class _LoRA_qkv(nn.Module):\n",
        "    def __init__(self, w_qkv, w_a, w_b, lora_alpha, lora_dropout):\n",
        "        super().__init__()\n",
        "        self.w_qkv = w_qkv\n",
        "        self.w_a = w_a #Project the input down to a lower-dimension space\n",
        "        self.w_b = w_b #Project the data in the lower-dimension space back to the original dimension\n",
        "        self.lora_alpha = lora_alpha #Scaling factor for the LoRA adjustments. It determines how much influence the LoRA-modified weights have.\n",
        "        self.dropout = nn.Dropout(lora_dropout) #Dropout rate\n",
        "        self.scaling = self.lora_alpha / self.w_a.weight.shape[0]  # alpha / r\n",
        "\n",
        "        self.weight = self.w_qkv.weight  # load original weights\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_qkv(x) + self.scaling * self.dropout(self.w_b(self.w_a(x)))\n",
        "\n",
        "class LoRAInitializer:\n",
        "    def __init__(self, model, r=None, lora=None, lora_alpha=32, lora_dropout=0.1):\n",
        "        if r is None:\n",
        "            r = [14, 14, 12, 12, 10, 10, 8, 8, 8, 8, 8, 8]#Prepared for 12 blocks of QKV blocks\n",
        "        if lora is None:\n",
        "            lora = ['q', 'v']\n",
        "\n",
        "        self.model = model\n",
        "        self.r = r\n",
        "        self.lora = lora\n",
        "        self.lora_alpha = lora_alpha\n",
        "        self.lora_dropout = lora_dropout\n",
        "        #ab matrix\n",
        "        self.w_As = []\n",
        "        self.w_Bs = []\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for w_A, w_B in zip(self.w_As, self.w_Bs):\n",
        "            # normal distribution init for w_A\n",
        "            nn.init.normal_(w_A.weight, mean=0.0, std=0.02)\n",
        "            nn.init.zeros_(w_B.weight)  # zero init for w_B\n",
        "    '''\n",
        "    将 Transformer 模型的 QKV 权重替换为带有 LoRA 的 _LoRA_qkv 模块。\n",
        "    冻结 Transformer 模型中的所有原始权重，使得在训练过程中仅 LoRA 参数（w_a 和 w_b）可训练\n",
        "    '''\n",
        "\n",
        "    def initialize_lora(self):\n",
        "        for param in self.model.transformer.parameters():\n",
        "            param.requires_grad = False  # freeze transformer parameters\n",
        "            # param.requires_grad = True\n",
        "\n",
        "        for t_layer_i, blk in enumerate(self.model.transformer.h):  # t_layer_i = [0, 11], blk = transformer block\n",
        "            # GPT2 uses a single c_attn for q, k, v\n",
        "            w_qkv = blk.attn.c_attn\n",
        "            in_features = w_qkv.weight.shape[0]  # 768\n",
        "            out_features = w_qkv.weight.shape[1]  # 2304\n",
        "\n",
        "            w_a_linear = nn.Linear(in_features, self.r[t_layer_i], bias=False)\n",
        "            w_b_linear = nn.Linear(self.r[t_layer_i], out_features, bias=False)\n",
        "            self.w_As.append(w_a_linear)\n",
        "            self.w_Bs.append(w_b_linear)\n",
        "            blk.attn.c_attn = _LoRA_qkv(w_qkv, w_a_linear, w_b_linear, self.lora_alpha, self.lora_dropout)\n",
        "\n",
        "        self.reset_parameters()\n",
        "        print(\"LoRA params initialized!\")\n",
        "        return self.model\n",
        "\n",
        "\n",
        "class BLIPGPTVQAGen(nn.Module):\n",
        "    def __init__(self, r=None, lora=None, lora_alpha=32, lora_dropout=0.1):\n",
        "        super(BLIPGPTVQAGen, self).__init__()\n",
        "\n",
        "        # gpt2 decoder\n",
        "        self.gpt = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "        self.gpt = LoRAInitializer(self.gpt, r=r, lora=lora, lora_alpha=lora_alpha,\n",
        "                       lora_dropout=lora_dropout).initialize_lora()  # add lora\n",
        "\n",
        "        # visual encoder\n",
        "        model_name = \"google/vit-base-patch16-224-in21k\"\n",
        "        self.visual_encoder = ViTModel.from_pretrained(model_name)\n",
        "\n",
        "        # tokenizer-GPT\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token  # end of string\n",
        "\n",
        "        # text encoder\n",
        "        config = BlipConfig.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "        self.text_encoder = BlipTextModel(config.text_config, add_pooling_layer=False)\n",
        "\n",
        "        # modify embedding layer\n",
        "        new_vocab_size = len(self.tokenizer)\n",
        "        embedding_dim = self.text_encoder.embeddings.word_embeddings.embedding_dim\n",
        "        self.text_encoder.embeddings.word_embeddings = nn.Embedding(new_vocab_size, embedding_dim)  # He init\n",
        "\n",
        "    def forward(self, image, question_inputs):\n",
        "        # visual encoder\n",
        "        image = image.to(device)\n",
        "        image_embeds = self.visual_encoder(image).last_hidden_state  # torch.Size([bs, 197, 768]) on default num_patches = 196(14*14), here +1 class toke; 768 is hidden dimension\n",
        "        image_atts = torch.ones(image_embeds.size()[:-1], dtype=torch.long).to(image.device)  # torch.Size([bs, 197])# attention mask 196,not 197?\n",
        "\n",
        "        question_input_ids = question_inputs['input_ids']  # torch.Size([bs, 25])25 is the longest length of the text\n",
        "        question_att_mask = question_inputs['attention_mask']\n",
        "\n",
        "        # multimodal encoder\n",
        "        text_output = self.text_encoder(input_ids=question_input_ids,\n",
        "                         attention_mask=question_att_mask,\n",
        "                         encoder_hidden_states=image_embeds,\n",
        "                         encoder_attention_mask=image_atts,\n",
        "                         return_dict=True)\n",
        "        text_embeds = text_output.last_hidden_state  # torch.Size([bs, 25, 768]), args.question_len=25\n",
        "\n",
        "        # text decoder\n",
        "        gpt_output = self.gpt(inputs_embeds=text_embeds,\n",
        "                              encoder_attention_mask=question_att_mask)  # torch.Size([bs, 25, 50257])\n",
        "        return gpt_output.logits"
      ],
      "metadata": {
        "id": "MmRX4VGiTvU3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "_erh0wbsXCoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, shrink_factor):\n",
        "    print(\"\\nDECAYING learning rate.\")\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
        "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "uhBXHt-wW8Tn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "yF8S896pVrVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import argparse\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# 挂载 Google Drive\n",
        "drive.mount('/content/drive')\n",
        "checkpoint_path = \"/content/drive/My Drive/Share_Weights/checkpoint.pth\"\n",
        "metrics_path = \"/content/drive/My Drive/Share_Weights/metrics.json\"\n",
        "#os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, metrics, best_epoch, checkpoint_path):\n",
        "    \"\"\"保存模型和训练状态到 Google Drive\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'metrics': metrics,\n",
        "        'best_epoch': best_epoch,\n",
        "    }\n",
        "    #save_path = os.path.join(drive_path, file_name)\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"Checkpoint saved\")\n",
        "\n",
        "def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    \"\"\"加载模型和训练状态\"\"\"\n",
        "    #load_path = os.path.join(drive_path, file_name)\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])  # 恢复模型权重\n",
        "        if optimizer:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  # 恢复优化器状态\n",
        "        print(f\"Checkpoint loaded from {checkpoint_path}\")\n",
        "        return checkpoint\n",
        "    else:\n",
        "        print(\"No checkpoint found, starting from scratch.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_metrics_to_drive(metrics, metrics_path):\n",
        "    \"\"\"保存评估结果到 Google Drive\"\"\"\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        json.dump(metrics, f, indent=4)\n",
        "    print(f\"Evaluation metrics saved to {save_path}\")\n",
        "\n",
        "def train(args, train_dataloader, model, criterion, optimizer, epoch, tokenizer, device):\n",
        "    model.train()\n",
        "    total_loss = AverageMeter()\n",
        "\n",
        "    for i, (_, images, questions, answers) in enumerate(tqdm(train_dataloader), 0):\n",
        "        question_inputs = tokenizer(questions, padding=\"max_length\", max_length=int(args.seq_length),\n",
        "                                    return_tensors=\"pt\", truncation=True)#truncation=True：截断超过最大长度的序列。 return_tensors=\"pt\"：返回 PyTorch 张量\n",
        "        answer_inputs = tokenizer(answers, padding=\"max_length\", max_length=int(args.seq_length),\n",
        "                                  return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "        # get logits and labels\n",
        "        logits = model(image=images.to(device), question_inputs=question_inputs.to(device))\n",
        "        # 文本生成模型的输出代表模型对每个位置的下一个词的预测\n",
        "        labels = answer_inputs['input_ids'].to(device)\n",
        "\n",
        "        # get shifted logits and labels\n",
        "        shift_logits = logits[:, :-1, :].contiguous()\n",
        "        shift_labels = labels[:, 1:].contiguous()\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss.update(loss.item())\n",
        "    print(\"Epoch: {}/{} Loss: {:.6f} AVG_Loss: {:.6f}\".format(epoch, args.epochs, total_loss.val, total_loss.avg))\n",
        "\n",
        "def validate(args, val_loader, model, criterion, epoch, tokenizer, device):\n",
        "    references = []\n",
        "    hypotheses = []\n",
        "\n",
        "    model.eval()\n",
        "    total_loss = AverageMeter()\n",
        "    with torch.no_grad():\n",
        "        for i, (_, images, questions, answers) in enumerate(tqdm(val_loader), 0):\n",
        "            question_inputs = tokenizer(questions, padding=\"max_length\", max_length=int(args.seq_length),\n",
        "                                        return_tensors=\"pt\", truncation=True)\n",
        "            answer_inputs = tokenizer(answers, padding=\"max_length\", max_length=int(args.seq_length),\n",
        "                                      return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "            # get logits and labels\n",
        "            logits = model(image=images.to(device), question_inputs=question_inputs.to(device))\n",
        "            labels = answer_inputs['input_ids'].to(device)\n",
        "\n",
        "            # get shifted logits and labels\n",
        "            shift_logits = logits[:, :-1, :].contiguous()\n",
        "            shift_labels = labels[:, 1:].contiguous()\n",
        "\n",
        "            # compute loss\n",
        "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            total_loss.update(loss.item())\n",
        "\n",
        "            # generate predicted answer\n",
        "            _, predicted = torch.max(logits, dim=-1)\n",
        "\n",
        "            # decode references and predictions\n",
        "            reference_answers = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "            predicted_answers = tokenizer.batch_decode(predicted, skip_special_tokens=True)\n",
        "\n",
        "            # add references and hypotheses to lists\n",
        "            for ref, hyp in zip(reference_answers, predicted_answers):\n",
        "                references.append([ref.split()])\n",
        "                hypotheses.append(hyp.split())\n",
        "\n",
        "        # Calculate BLEU_1~4\n",
        "        metrics = {}\n",
        "        metrics[\"Bleu_1\"] = corpus_bleu(references, hypotheses, weights=(1.00, 0.00, 0.00, 0.00))\n",
        "        metrics[\"Bleu_2\"] = corpus_bleu(references, hypotheses, weights=(0.50, 0.50, 0.00, 0.00))\n",
        "        metrics[\"Bleu_3\"] = corpus_bleu(references, hypotheses, weights=(0.33, 0.33, 0.33, 0.00))\n",
        "        metrics[\"Bleu_4\"] = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "        print(f\"Epoch: {epoch}/{args.epochs} EVA LOSS: {total_loss.avg:.6f} \"\n",
        "              f\"BLEU-1: {metrics['Bleu_1']:.6f} BLEU-2: {metrics['Bleu_2']:.6f} \"\n",
        "              f\"BLEU-3: {metrics['Bleu_3']:.6f} BLEU-4: {metrics['Bleu_4']:.6f}\")\n",
        "    return metrics\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.epochs = 20\n",
        "        self.batch_size = 8\n",
        "        self.workers = 8\n",
        "        self.random_seed = 42\n",
        "        self.seq_length = 32\n",
        "        self.lr = 0.00002\n",
        "\n",
        "        self.vector_rank = [14, 14, 12, 12, 10, 10, 8, 8, 8, 8, 8, 8]\n",
        "        self.lora_alpha = 32\n",
        "        self.lora_dropout = 0.1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQBpj1WhUqgu",
        "outputId": "47044d61-581f-4e2d-e9f9-f168c3031dc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    checkpoint_path = \"/content/drive/My Drive/Share_Weights/checkpoint.pth\"\n",
        "    metrics_path = \"/content/drive/My Drive/Share_Weights/metrics.json\"\n",
        "    args = Args()\n",
        "    os.makedirs('./checkpoints/', exist_ok=True)\n",
        "\n",
        "    seed_everything(args.random_seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_epoch = [0]\n",
        "    best_results = [0.0]\n",
        "    epochs_since_improvement = 0\n",
        "\n",
        "    # data location\n",
        "    train_seq = [2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15]\n",
        "    val_seq = [1, 5, 16]\n",
        "\n",
        "    folder_head = '/content/PitVQA/datasets/EndoVis-18-VQA/seq_'\n",
        "    folder_tail = '/vqa/Sentence/*.txt'\n",
        "\n",
        "    # dataloader\n",
        "    train_dataset = EndoVis18VQAGPTGen(train_seq, folder_head, folder_tail)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "    val_dataset = EndoVis18VQAGPTGen(val_seq, folder_head, folder_tail)\n",
        "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f'num of elements: {len(args.vector_rank)}')\n",
        "    model = BLIPGPTVQAGen(r=args.vector_rank, lora_alpha=args.lora_alpha, lora_dropout=args.lora_dropout)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)  # same learning rate for LoRA weights and other weights\n",
        "\n",
        "    model = model.to(device)\n",
        "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "    print('model params: ', pytorch_total_params)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    #read check point\n",
        "    checkpoint = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "    if checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_results = checkpoint['metrics']\n",
        "        best_epoch = checkpoint['best_epoch']\n",
        "        print(f\"Resuming training from epoch {start_epoch} with best BLEU-4: {best_results['Bleu_4']} at epoch {best_epoch}\")\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        best_results = {\"Bleu_4\": 0.0}\n",
        "        best_epoch = [0]\n",
        "\n",
        "\n",
        "    print('Start training.')\n",
        "    for epoch in range(start_epoch, args.epochs+1):\n",
        "\n",
        "        if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
        "            adjust_learning_rate(optimizer, 0.8)\n",
        "\n",
        "        # train\n",
        "        train(args, train_dataloader=train_dataloader, model=model, criterion=criterion, optimizer=optimizer,\n",
        "              epoch=epoch, tokenizer=tokenizer, device=device)\n",
        "        # validation\n",
        "        metrics = validate(args, val_loader=val_dataloader, model=model, criterion=criterion, epoch=epoch,\n",
        "                           tokenizer=tokenizer, device=device)\n",
        "\n",
        "        if metrics[\"Bleu_4\"] >= best_results[\"Bleu_4\"]:\n",
        "            epochs_since_improvement = 0\n",
        "            best_results[\"Bleu_4\"] = metrics[\"Bleu_4\"]\n",
        "            best_epoch[0] = epoch\n",
        "            print(f'Best epoch: {epoch}, Best Bleu_4: {metrics[\"Bleu_4\"]}')\n",
        "        else:\n",
        "            epochs_since_improvement += 1\n",
        "            print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
        "\n",
        "        save_checkpoint(model, optimizer, epoch, metrics, best_epoch, checkpoint_path)\n",
        "        save_metrics_to_drive(metrics, metrics_path)\n",
        "        print(\"finish saving\")\n",
        "    print('End training.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyfLJBzhn48m",
        "outputId": "3ee092d0-187e-45af-a6bd-95340d2681fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files: 1560 | Total question: 10574\n",
            "Total files: 447 | Total question: 3216\n",
            "num of elements: 12\n",
            "LoRA params initialized!\n",
            "model params:  363611136\n",
            "Checkpoint loaded from /content/drive/My Drive/Share_Weights/checkpoint.pth\n",
            "Resuming training from epoch 3 with best BLEU-4: 0.6287180750028531 at epoch [2]\n",
            "Start training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 15/1322 [00:09<13:30,  1.61it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 定义保存路径\n",
        "save_path = '/content/drive/MyDrive/checkpoints/manual_checkpoint.pth'\n",
        "\n",
        "# 保存当前状态\n",
        "state = {\n",
        "    'epoch': current_epoch,  # 替换为当前 epoch\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}\n",
        "torch.save(state, save_path)\n",
        "print(f\"Checkpoint saved at {save_path}\")\n"
      ],
      "metadata": {
        "id": "4vcBFPbzgbeJ",
        "outputId": "89c9392d-eb9d-4417-ecce-c0786377fe42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'current_epoch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2e6fe9e0bbb8>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 保存当前状态\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m state = {\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 替换为当前 epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'current_epoch' is not defined"
          ]
        }
      ]
    }
  ]
}