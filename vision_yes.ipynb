{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterHJY628/MyOwnExample/blob/main/vision_yes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"torch==2.4.0\" tensorboard pillow torchvision accelerate huggingface_hub\n",
        "!pip -q install  --upgrade \\\n",
        "  \"transformers==4.45.1\" \\\n",
        "  \"datasets==3.0.1\" \\\n",
        "  \"accelerate==0.34.2\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.44.0\" \\\n",
        "  \"trl==0.11.1\" \\\n",
        "  \"peft==0.13.0\" \\\n",
        "  \"qwen_vl_utils\""
      ],
      "metadata": {
        "id": "31hYynMQalOW",
        "outputId": "fa0e0210-d31b-4136-a695-d19c2ff92956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "31hYynMQalOW",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6XTxQsAahAV",
        "outputId": "fedf1f54-0428-4301-8644-4a85dd8e8d76"
      },
      "id": "j6XTxQsAahAV",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "66767b92-5bef-443d-a8dd-c3cc5add2e32",
      "metadata": {
        "id": "66767b92-5bef-443d-a8dd-c3cc5add2e32",
        "outputId": "c9277f78-0542-4871-df5a-62bf0556fafc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/sa5u24/VQA\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['HF_HOME'] = '/home/sa5u24/VQA'\n",
        "hf_home = os.path.expanduser(\n",
        "    os.getenv(\"HF_HOME\", os.path.join(os.getenv(\"XDG_CACHE_HOME\", \"~/.cache\"), \"huggingface\"))\n",
        ")\n",
        "print(hf_home)\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Replace 'your-hf-token-here' with your actual Hugging Face token\n",
        "login(token=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6046b99b-1f55-499b-bb7f-8fd1ac0edbe6",
      "metadata": {
        "id": "6046b99b-1f55-499b-bb7f-8fd1ac0edbe6"
      },
      "outputs": [],
      "source": [
        "system_message = \"\"\" You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
        "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
        "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
        "The agent may call more than one model sequentially or in parallel based on query.\n",
        "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
        "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
        "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
        "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
        "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
        "\"\"\"\n",
        "\n",
        "def format_data(sample):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"Agent\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": system_message\n",
        "                }\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                # {\n",
        "                #     \"type\": \"image\",\n",
        "                #     \"image\": None,\n",
        "                # },\n",
        "                # {\n",
        "                #     \"type\": \"image\",\n",
        "                #     \"image\": sample[\"image\"],\n",
        "                # },\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": sample[0]\n",
        "                }\n",
        "            ],\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": sample[1]\n",
        "                }\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_id = \"HuggingFaceM4/ChartQA\"\n",
        "train_dataset, eval_dataset, test_dataset = load_dataset(dataset_id, split=['train[:10%]', 'val[:10%]', 'test[:10%]'])\n",
        "\n",
        "train_dataset = [format_data(sample) for sample in train_dataset]\n",
        "eval_dataset = [format_data(sample) for sample in eval_dataset]\n",
        "test_dataset = [format_data(sample) for sample in test_dataset]\n",
        "\n",
        "train_dataset[200], len(train_dataset), len(eval_dataset), len(test_dataset)"
      ],
      "metadata": {
        "id": "e776ZyBAnZ5G",
        "outputId": "afdc7b27-8460-4804-ed0c-31de6149b63c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e776ZyBAnZ5G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'role': 'system',\n",
              "   'content': [{'type': 'text',\n",
              "     'text': 'You are a Vision Language Model specialized in interpreting visual data from chart images.\\nYour task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\\nThe charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\\nFocus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.'}]},\n",
              "  {'role': 'user',\n",
              "   'content': [{'type': 'text',\n",
              "     'text': 'Is the rightmost value of light brown graph 58?'}]},\n",
              "  {'role': 'assistant', 'content': [{'type': 'text', 'text': 'No'}]}],\n",
              " 2830,\n",
              " 192,\n",
              " 250)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch  # Import torch for dataset splitting and other PyTorch functionalities\n",
        "from torch.utils.data import Dataset, DataLoader  # For creating PyTorch Dataset and DataLoader\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access the file\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class TextQuestionLabelDataset(Dataset):\n",
        "    def __init__(self, input_file):\n",
        "        # Load data from a CSV file\n",
        "        self.data = pd.read_csv(input_file)\n",
        "        print(self.data.head())  # 显示前 5 行数据\n",
        "\n",
        "\n",
        "        # Extract questions and labels from the Input column\n",
        "        #self.questions = self.data['Input'].apply(lambda x: re.search(r'Question: (.+?)\\n', x).group(1)).tolist()\n",
        "        self.questions = self.data['Input'].tolist()\n",
        "        self.labels = self.data['Label'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a single sample (question, label) given an index\n",
        "        question = self.questions[idx]\n",
        "        label = self.labels[idx]\n",
        "        return question, label\n",
        "\n",
        "input_file = '/content/drive/My Drive/test50.csv'\n",
        "\n",
        "# Initialize dataset\n",
        "dataset = TextQuestionLabelDataset(input_file)\n",
        "\n",
        "# Split the dataset for train, eval, and test (e.g., 10% for each)\n",
        "dataset_length = len(dataset)\n",
        "#train_size = int(0.1 * dataset_length)\n",
        "train_size = 0\n",
        "#eval_size = int(0.1 * dataset_length)\n",
        "eval_size = 0\n",
        "test_size = dataset_length - train_size - eval_size\n",
        "\n",
        "train_dataset, eval_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset, [train_size, eval_size, test_size]\n",
        ")\n",
        "#print(train_dataset[0])\n",
        "train_dataset = [format_data(sample) for sample in train_dataset]\n",
        "eval_dataset = [format_data(sample) for sample in eval_dataset]\n",
        "test_dataset = [format_data(sample) for sample in test_dataset]\n",
        "\n",
        "# Create DataLoaders for batching\n",
        "# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "# eval_loader = DataLoader(eval_dataset, batch_size=2, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "test_dataset[0]\n",
        "# print(\"Train Dataset Example:\")\n",
        "# for question, label in train_loader:\n",
        "#     print(\"Question:\", question)\n",
        "#     print(\"Label:\", label)\n",
        "#     break  # Print only the first batch for demonstration\n",
        "\n",
        "# print(\"\\nEvaluation Dataset Example:\")\n",
        "# for question, label in eval_loader:\n",
        "#     print(\"Question:\", question)\n",
        "#     print(\"Label:\", label)\n",
        "#     break\n",
        "\n",
        "# print(\"\\nTest Dataset Example:\")\n",
        "# for question, label in test_loader:\n",
        "#     print(\"Question:\", question)\n",
        "#     print(\"Label:\", label)\n",
        "#     break\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0idS6tUnWhuz",
        "outputId": "0e51c16b-ea5f-4c09-bf4f-756927556104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0idS6tUnWhuz",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Index                          Type  \\\n",
            "0      1  Detection|Segmentation_Video   \n",
            "1      2                  Surgical-VQA   \n",
            "2      3                   Segment-MRI   \n",
            "3      4                    Overlaying   \n",
            "4      5               Detection-Video   \n",
            "\n",
            "                                               Input  \\\n",
            "0  Question: Detect instruments in video and over...   \n",
            "1   Question: Analyze the instruments in this phase.   \n",
            "2  Question: Locate and segment the optic protube...   \n",
            "3  Question: Merge the tumor segmentation images ...   \n",
            "4  Question: Can you identify the instruments pre...   \n",
            "\n",
            "                                               Label  \n",
            "0  Model: Detection|Segmentation_Video\\nPrompt: D...  \n",
            "1  Model: Surgical-VQA\\nPrompt: analyze the instr...  \n",
            "2  Model: Segment-MRI\\nPrompt: Segment optic prot...  \n",
            "3  Model: Overlaying\\nPrompt: Overlay tumor segme...  \n",
            "4  Model: Detection-Video\\nPrompt: can you identi...  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'Agent',\n",
              "  'content': [{'type': 'text',\n",
              "    'text': ' You are an LLM agent which can call functions and corresponding prompt based on surgeons\\' query.\\nThe agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection,\\xa0Overlaying, Surgical-VQA.\\nThere are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\\nThe agent may call more than one model sequentially or in parallel based on query.\\nYour task is to analyze the user\\'s query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\\nIf you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\\nPrompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,\\xa0 Overlaying, Surgical-VQA].\\nIf you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\\nPrompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,\\xa0 Overlaying, Surgical-VQA].\\n'}]},\n",
              " {'role': 'user',\n",
              "  'content': [{'type': 'text',\n",
              "    'text': 'Question: Can you identify the instruments present in the video?'}]},\n",
              " {'role': 'assistant',\n",
              "  'content': [{'type': 'text',\n",
              "    'text': 'Model: Detection-Video\\nPrompt: can you identify the instruments present in the video?'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b309522e-b40b-4289-87e9-d28c27b81678",
      "metadata": {
        "id": "b309522e-b40b-4289-87e9-d28c27b81678"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import time\n",
        "\n",
        "def clear_memory():\n",
        "    # Delete variables if they exist in the current global scope\n",
        "    if 'inputs' in globals(): del globals()['inputs']\n",
        "    if 'model' in globals(): del globals()['model']\n",
        "    if 'processor' in globals(): del globals()['processor']\n",
        "    if 'trainer' in globals(): del globals()['trainer']\n",
        "    if 'peft_model' in globals(): del globals()['peft_model']\n",
        "    if 'bnb_config' in globals(): del globals()['bnb_config']\n",
        "    time.sleep(2)\n",
        "\n",
        "    # Garbage collection and clearing CUDA memory\n",
        "    gc.collect()\n",
        "    time.sleep(2)\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.synchronize()\n",
        "    time.sleep(2)\n",
        "    gc.collect()\n",
        "    time.sleep(2)\n",
        "\n",
        "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "\n",
        "\n",
        "\n",
        "def generate_text_from_sample(model, processor, sample, max_new_tokens=1024, device=\"cuda\"):\n",
        "    # Prepare the text input by applying the chat template\n",
        "    text_input = processor.apply_chat_template(\n",
        "        sample[:2],  # Use the sample without the system message\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "    print(\"Text Input:\", text_input)\n",
        "\n",
        "\n",
        "    # Process the visual input from the sample\n",
        "    # image_inputs, _ = process_vision_info(sample)\n",
        "    #image_inputs = sample[1]['content'][0]['image'].convert(\"RGB\")\n",
        "    image_data = sample[1]['content'][0].get('image')\n",
        "\n",
        "    if image_data is not None:\n",
        "        image_inputs = image_data.convert(\"RGB\")\n",
        "    else:\n",
        "        # 提供一个默认值或适当的处理逻辑\n",
        "        image_inputs = None\n",
        "        #print(\"Warning: The 'image' field is None.\")\n",
        "    # Prepare the inputs for the model\n",
        "    model_inputs = processor(\n",
        "        text=[text_input],\n",
        "        images=image_inputs,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)  # Move inputs to the specified device\n",
        "\n",
        "    # Generate text with the model\n",
        "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n",
        "\n",
        "    # Trim the generated ids to remove the input ids\n",
        "    trimmed_generated_ids = [\n",
        "        out_ids[len(in_ids):] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    # Decode the output text\n",
        "    output_text = processor.batch_decode(\n",
        "        trimmed_generated_ids,\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=False\n",
        "    )\n",
        "\n",
        "    return output_text[0]  # Return the first decoded output text\n",
        "\n",
        "# def generate_text_from_sample(model, processor, question, max_new_tokens=1024, device=\"cuda\"):\n",
        "#     \"\"\"\n",
        "#     Generate text from a sample using the model and processor.\n",
        "\n",
        "#     Args:\n",
        "#         model: The model used for generation.\n",
        "#         processor: The processor for preparing inputs.\n",
        "#         question: The input question as a string.\n",
        "#         max_new_tokens: The maximum number of tokens to generate.\n",
        "#         device: The device to use for computation (\"cuda\" or \"cpu\").\n",
        "\n",
        "#     Returns:\n",
        "#         A string containing the generated output text.\n",
        "#     \"\"\"\n",
        "#     # Prepare the text input directly from the question\n",
        "#     text_input = processor.apply_chat_template(\n",
        "#         [question],  # Directly use the question\n",
        "#         tokenize=False,\n",
        "#         add_generation_prompt=True\n",
        "#     )\n",
        "\n",
        "#     # Handle the case where no image is provided\n",
        "#     image_inputs = None  # No visual input in the current dataset\n",
        "\n",
        "#     # Prepare the inputs for the model\n",
        "#     model_inputs = processor(\n",
        "#         text=[text_input],\n",
        "#         images=image_inputs,\n",
        "#         return_tensors=\"pt\",\n",
        "#     ).to(device)  # Move inputs to the specified device\n",
        "\n",
        "#     # Generate text with the model\n",
        "#     generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n",
        "\n",
        "#     # Trim the generated ids to remove the input ids\n",
        "#     trimmed_generated_ids = [\n",
        "#         out_ids[len(in_ids):] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "#     ]\n",
        "\n",
        "#     # Decode the output text\n",
        "#     output_text = processor.batch_decode(\n",
        "#         trimmed_generated_ids,\n",
        "#         skip_special_tokens=True,\n",
        "#         clean_up_tokenization_spaces=False\n",
        "#     )\n",
        "\n",
        "#     return output_text[0]  # Return the first decoded output text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e56e15-fd77-4664-a9c9-dfa610d0ddee",
      "metadata": {
        "id": "e0e56e15-fd77-4664-a9c9-dfa610d0ddee",
        "outputId": "bf0f8c14-0df1-4910-b7bd-fe4e15aff94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU allocated memory: 7.16 GB\n",
            "GPU reserved memory: 7.27 GB\n"
          ]
        }
      ],
      "source": [
        "clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a45230ca-ca62-439d-8984-398cb07db7e4",
      "metadata": {
        "id": "a45230ca-ca62-439d-8984-398cb07db7e4",
        "outputId": "6d7140ae-6702-4654-f7d7-0f52b13d0d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618,
          "referenced_widgets": [
            "b257eab5f5a540fc8e1a6141deb5dc0a",
            "d6432ea28e1848bfa837507ae143c102",
            "5508dcc897de40d2ad2911981a610c8e",
            "4601df29480f4609b1d3667221c2b782",
            "083885a160f74cb8a88524460b14cdc6",
            "e033b9cec6c1470caaa20bc30aa530f1",
            "bd6c26ba6d4f4198902c88978d03e5aa",
            "07d3ae19bb8142d2b434843c298fc86b",
            "74198e64efdd4d8c85252b1225246230",
            "a89c365723a248698bde13eb2488db87",
            "4d669d28b0d94a848348cf9e0b10ae5c",
            "6a8e527aaabf4921b7aa7e00756d1ef6",
            "44108ab511934f98ace0deba376de114",
            "b8d610dbe40e4ca993aa267f88b0a0ff",
            "e7dc7c06b3ff4370b115f1f0ba4cf98f",
            "c8776c5664e04b6da4674b1d6f2b32f8",
            "7e2467cbb2b34680bc69cca3ef583ef3",
            "e913023140314001be99e71afa9b53b0",
            "726f30f1cf8c495aa2ce4088d8e15d82",
            "0149518f1a3f4d8cb19c865f05b68919",
            "860b6c3d2e9c48e89364238e302edcd9",
            "62cf37d220894b9182eb8b75b516b607",
            "7701ec2b0dac41b5bbb539a3995e1741",
            "3d882d8188784dbd9991a31955214b9f",
            "29cd72d2b78940fb96be87b82225ea51",
            "8ce1698c0310409589a9123ca32d33c8",
            "3b5d915497794237977763634884593e",
            "2afd33b154674527a22f64335046a901",
            "6a9f05867e364145a9937beaa6fe9ee1",
            "d2bd666285404cef88362478de3dcc8c",
            "af34de6f27704eeab99d71f88ab8b31d",
            "23920a61e87247cda96c97c960d2c9a8",
            "2fd52311eb694801bb79b3174747622d",
            "1b9f99a65ca94814a17831eb7efc5586",
            "243d4d1ca75d4a4895b90612af4abb7c",
            "baaef3ce4d4b49f59b107676fabf0493",
            "c37a1157373a46288d0f6bb6a3255f6e",
            "9fdbab9e7f3c4538beec3a0f48efa2cf",
            "41ad0044bb2645a588ead85cf9a24406",
            "c905417875c3457e823cc99d298cf3c8",
            "cae9d411ac30490a956970b51d6c1e37",
            "3a85d5dea72a44148f02bbdc9a7ba6f6",
            "2d86dd41bc7343479cad3dc78fed3683",
            "42ce59ef2aec447d8363455c6d25d8dd",
            "9f2e63bfc89145e890e404a7012c445c",
            "942e36879ae349fd8ebac633bb9a3a2b",
            "3236b4ad543d40b7a71ee6485bdbc511",
            "36bd4fcb74874a75afbdf1c85540017a",
            "14e3bc65e92447ab91072ccc9933b0b3",
            "8ad14eaa908d4a7a97711540e3cea21a",
            "9ce694e4fedd487f8d990132d252978e",
            "a6b65406142b499e8c81958a63f510d5",
            "3fb2ede9531c4dd099380ead6d14b4e3",
            "4ed65dcb42ef4142b2485ce4ba2219f1",
            "607ae9c3e556497e920889e36c96d131",
            "bc76413bc788476aa5213474859b4bb2",
            "979b4d48a7294c599edeca5147b8878e",
            "603337f24f0e4becb7c21bea97f28b48",
            "85a137be1cf648978be378e0008b113b",
            "61a2a8bc993d4b3691ce65dc09f82c67",
            "2ba7ee6275a846d3ad979321bc2175d9",
            "dcfdb656bdb1488eabc248abfa495558",
            "ac0ecf9a9ce0434da2e3996e67c333a5",
            "b7584c5cdaa24a7eb0674f9c422abf2a",
            "60a54a6d4286465fa8896b0c8374e9d1",
            "5e266cd4871f47728e28005cb162c98f",
            "013f0a9b1d264a3ea6973e4974a059cf",
            "6ae4cf4fdd964f38a1a1da50c078c20a",
            "a1effd358375431e92414c2fb2fc5b33",
            "562a78514010451eaebcd1290db29f15",
            "4ccab6936a19405abf838c5160d201c2",
            "d84970f98e4b41ad9b057be8f104c2da",
            "8ad00f9d6f4746578d45b4f92d14e913",
            "1524eb992f4b4334af3679a54adb2886",
            "0d0960554886483d8872aeaad7839e0b",
            "906b9410515348649a8efab5c643a6f9",
            "c9b6f745feda4d03af21abd0070ee51d",
            "82f29a686d2b4765acb6c5f40ec0df34",
            "be74bd0dd49f47778d993e137601ba4a",
            "156529890d01435689798a0009803161",
            "ebd62e4c42304d198c24f4ed924c9542",
            "bc752736e8c94b2eaab44a932041ccf6",
            "d2cc7cfc5c854fd18e58684dbe199be7",
            "47d428a0fb0946039b2ccbac548ebb49",
            "c1bd5bd357134397943408177d832f2c",
            "b7f14ee4b3ad4081b78ee15e9ad40147",
            "166a0e264daa44219d31ecbdfb067573",
            "3901714efe894f17988f9241bbd49aed",
            "4429f342e8f64c4eab9f8b30f2e6cf63",
            "e4fd2c30c0d84253bc7ff3607b3c09d4",
            "8c5e18361a804401967f2fd24f9672f7",
            "64811cc516684c06844734fd6d1287fc",
            "c3e27cc60fea43088c970b56fb3a8587",
            "33d3635d82074e2a9dab366a6f07dd29",
            "fd92fb47a14b46558acee7ee076e8053",
            "94363358229b4ef8b259f8e24a6c9d18",
            "bcf8c329878e40039d66a528e5c01925",
            "4d050334b0a846df913c6ce5dedec58a",
            "00717e97d6584cc3a9d5ade74dd3b985",
            "8bd677af4c1449008c9953ff63f5a9bd",
            "53023f6973b341bc91de002fd8a59382",
            "6141f69345ef4b0cb1ba467f1103a490",
            "b2482a8a41914603b5f3f74b12ad4768",
            "9286c7b03b06496da27c9d282d2bfff4",
            "429dec557cdb4a80bcab7a6176418eb9",
            "57fcdd66f27d4c6fbf4284e45f89fe5e",
            "5875fc1541d647788575f4a7fde87e9e",
            "e92a27da2ba6484fa815068947753cbf",
            "4edb5ca7df5742878ef4d714c1439bb2",
            "1fc2f0f1f3d74452a4fecc3c1deac23c",
            "dd00e40dcb41407eae010cd4b3af7203",
            "754a82c540c24bed826928735c0c5d2d",
            "c070b4047eec49a2bdaca25ff46cfce6",
            "bd6432b6fdc74217a7e7da1c7010c207",
            "f4868893ea424cf1825170141abd2502",
            "08cadc27505e4efbb8c973f374460a6e",
            "835c4e33c06c4ea491a17783f033123c",
            "f39881d1fd0d4b6ca0188449a3a0a119",
            "9338d39ebbbb4b3eaf03cc7e18248e27",
            "6e5774452ea6455b99cd70c62e7c63bb",
            "ecc26e03a15c4728856ded157d901252",
            "240b71cb3b924d1580316a09a139050e",
            "ed2e7273330041199adf85f77f94a659",
            "7cfd0adc72194c2cac64bd57fc2e7a75",
            "9dc3b8161e2640419794b09d4a7791ba",
            "d7b13982bc2a41d1a174f4fbcb2e25ea",
            "8987d98778964c59b418e6cf63aab206",
            "ca503b9c005d46398e25aeab5b4bdb30",
            "3577b37273bb4cd5b54ead66e7c074a4",
            "84eb9764084a4f88b769b14055cd381e",
            "95272298f2b04d45835de2316a73245c",
            "4ce0627561764eedbe58a831f0b70a7f",
            "630055cda41c4473a8b9406844625889",
            "87eac49948f24486b9c75d672ce5fcb4",
            "c24115a725ab410dac8c1aea319daceb",
            "ab3904ad9eba40faad5f8daf2b878cba",
            "6fec99e10b74465da2338eb4873e854f",
            "d67aeb20297b47f0990f608f29beee7c",
            "51cb613b134941d1989b47e8a629b948",
            "765c332077254178a15bab6fa1a5a343",
            "d3d9a818191a4333bd542253a676be94",
            "b2d7958ea77c434784693bf5649d8d57",
            "65db0f9366304a4d9536b933d5026841",
            "fbbd01e12a7f4d8d8711e14d8589e045",
            "b70ff35f31d44c2bbe58f96120d62ea6",
            "cb118f0718f24b6db23a04e2b4571025",
            "f69a00d75cfe4234a820d8e10159700d",
            "d85b7e1bff2a4beda7c97681cf901eed",
            "5728c845e347478cbbf4913b37fcf4a3",
            "d72de1ae238842b791c9c33eae2c665f",
            "07e00276353449028143544eafb1fce4",
            "b1010c483e2949ec925915e6b23d1cec",
            "d86deb56eca8417ca4f035862a071c9d",
            "d0b1b5c85baa4dc0b80e2e1f45aec7f6",
            "9bd228ff43d5446bbcb6d9bcd06bcd7e",
            "96f4994cda84462b9fbfe5624ad94f79",
            "10311269dbc44f5fb993726c5ddfa26e",
            "eae033ef9032420487cfc300a63f027d",
            "83bd8677dfc04645abc5276071fe6b72",
            "b763ad02dbdb47d5a1032a231d6fc94a",
            "06ad4cf03d4045558d8164e8a0f3241b",
            "a93f430d1da945ef9967afdf3be98411",
            "48da9892beb746d4b8dd4b33d4972bee",
            "ea46395b281c42fcbc7283e0b53eb720",
            "60733d96a20247e2bc384e9ab9452a57"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b257eab5f5a540fc8e1a6141deb5dc0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/55.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a8e527aaabf4921b7aa7e00756d1ef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/5.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7701ec2b0dac41b5bbb539a3995e1741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b9f99a65ca94814a17831eb7efc5586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f2e63bfc89145e890e404a7012c445c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/5.09k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc76413bc788476aa5213474859b4bb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/89.4k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "013f0a9b1d264a3ea6973e4974a059cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f29a686d2b4765acb6c5f40ec0df34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00005.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4429f342e8f64c4eab9f8b30f2e6cf63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00005.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bd677af4c1449008c9953ff63f5a9bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd00e40dcb41407eae010cd4b3af7203"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "240b71cb3b924d1580316a09a139050e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00005-of-00005.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "630055cda41c4473a8b9406844625889"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbbd01e12a7f4d8d8711e14d8589e045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bd228ff43d5446bbcb6d9bcd06bcd7e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import evaluate\n",
        "import torch\n",
        "from nltk.translate.meteor_score import meteor_score, single_meteor_score\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "import requests\n",
        "from torch import nn\n",
        "from transformers import MllamaForConditionalGeneration, AutoProcessor, MllamaConfig, AutoModelForCausalLM\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    # low_cpu_mem_usage=True,\n",
        "    # bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "            model_id, torch_dtype=torch.bfloat16, device_map=\"auto\", low_cpu_mem_usage=True,\n",
        "            quantization_config=quantization_config,\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_pred = []\n",
        "all_ans = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for sample in test_dataset:\n",
        "        output = generate_text_from_sample(model, processor, sample)\n",
        "        ans = sample[2]['content'][0]['text']\n",
        "        all_pred.append(output)\n",
        "        all_ans.append(ans)\n",
        "\n",
        "# all_pred = []\n",
        "# all_ans = []\n",
        "\n",
        "# model.eval()  # 切换到评估模式\n",
        "# with torch.no_grad():  # 禁用梯度计算\n",
        "#     for question, label in test_loader:  # 遍历测试数据加载器\n",
        "#         # 将问题输入模型，生成预测结果\n",
        "#         # 假设 generate_text_from_sample 是用于推理的函数\n",
        "#         output = [generate_text_from_sample(model, processor, q) for q in question]\n",
        "\n",
        "#         # 将预测结果和真实标签保存\n",
        "#         all_pred.extend(output)\n",
        "#         all_ans.extend(label)\n",
        "\n",
        "# # 打印结果，或者使用 all_pred 和 all_ans 计算指标\n",
        "# print(\"Predictions:\", all_pred)\n",
        "# print(\"Answers:\", all_ans)\n"
      ],
      "metadata": {
        "id": "q7PWaz-aZU-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb027e72-47c5-48e0-9476-281759be70bf"
      },
      "id": "q7PWaz-aZU-B",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Can you identify the instruments present in the video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Integrate anatomy segmentation with the current surgical view?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment anatomical structures in MRI and identify regions of interest in the surgical scene?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Analyze and segment Left Optic Protuberance from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment anatomy and tumor from MRI?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Can you segment Clival Recess from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Show an overlay of preoperative imaging and the surgical frame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Which instrument quantities is being used?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Locate the instruments in the surgical scene.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Explain the role of the phases in this step.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment the region of Left Carotid from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: What is the position of the operation notes?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Merge the tumor segmentation images with surgical video in real-time?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: What surgical instruments can be detected in the video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Show an overlay of preoperative imaging and the surgical frame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment anatomy and tumor from MRI?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Can you overlay the preoperative imaging on the surgical video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Find all the instruments visible in this video frame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Provide an overlay of diagnosis MRI and surgical scene?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Overlay diagnostic MRI on surgical video and detect tool positions?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Overlay preoperative imaging with the surgical scene and identify instruments?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: What surgical instruments can be detected in the video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Show an overlay of anatomy segmentation and the surgical frame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Can you overlay the anatomy segmentation on the surgical video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Analyze the instruments in this phase.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Detect instruments in video and overlay diagnostic diagnostic MRI?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Describe the steps being used.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Analyze the current phase and segment optic protuberances in video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Find all the instruments visible in this video frame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Precisely segment the tumor from MRI data?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Overlay tumor segmentation with the surgical scene and identify tool positions?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: What surgical instruments can be detected in the video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Combine preoperative imaging and surgical visuals into an overlay?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Detect instruments in video and overlay diagnostic tumor segmentation?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Which instrument positions is being used?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Perform segmentation of Left Optic Protuberance from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment Right Optic Protuberance in the current frame of Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Locate the instrument quantities in the surgical scene.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Locate and segment the optic protuberances region in MRI?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Which instruments is being used?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Display an overlay of anatomy segmentation on the surgical field?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Locate and segment Clival Recess from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Precisely segment Left Optic Protuberance from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment tumor margins from MRI and overlay on video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Perform segmentation of clival recess using MRI?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Overlay diagnosis MRI and highlight anatomical structures?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Segment the anatomical structure of Clival Recess from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Show an overlay of diagnosis MRI and the surgical frame?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: Locate and segment Sella from Video?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "Text Input: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 08 Jan 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>Agent<|end_header_id|>\n",
            "\n",
            " You are an LLM agent which can call functions and corresponding prompt based on surgeons' query.\n",
            "The agent will be used in endonasal pituitary surgery to call visual models Segmentation_Video, Segmentation_MRI, Detection, Overlaying, Surgical-VQA.\n",
            "There are 59 classes overall, including 4 phases, 15 steps, 18 instruments, 3 variations of instruments present in a frame, 5 positions of the instruments, and 14 operation notes in the annotation classes.\n",
            "The agent may call more than one model sequentially or in parallel based on query.\n",
            "Your task is to analyze the user's query, determine the intent, and return the name of the AI model to be invoked along with the corresponding prompt.\n",
            "If you receive the input like: \"Question: Segment tumor from MRI and overlay on video?\" The format of the answer should be like this: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment tumor from MRI?|Overlay on video?\" This is the format for the answers may need more than one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "If you receive the input like: \"Question: Segment Sella from Video?\" The format of the answer should be like this: Model: Segment-Video\n",
            "Prompt: Segment Sella from video?\" This is the format for the answers need only one model. The model options are Model Options: [Segmentation_Video, Segmentation_MRI, Detection,  Overlaying, Surgical-VQA].\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Question: What observation can be made about the steps?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b2591d13-d5de-4107-99d6-95aa50682dbd",
      "metadata": {
        "id": "b2591d13-d5de-4107-99d6-95aa50682dbd",
        "outputId": "2cd3f9e3-5bb4-421a-d946-ca1ab436ad98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred: Model: Detection\n",
            "Prompt: Identify instruments present in the video?\n",
            "ans: Model: Detection-Video\n",
            "Prompt: can you identify the instruments present in the video?\n",
            "pred: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Integrate anatomy segmentation with the current surgical view?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation with surgical scene.\n",
            "pred: Model: Segmentation_MRI, Detection\n",
            "Prompt: Segment anatomical structures from MRI? Identify regions of interest in the surgical scene?\n",
            "ans: Model: Overlaying|Surgical-VQA\n",
            "Prompt: Segment anatomical structures in MRI?|Identify regions of interest in the surgical scene?\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Analyze and segment Left Optic Protuberance from video?\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Analyze left optic protuberance?\n",
            "pred: Model: Segmentation_MRI\n",
            "Prompt: Segment anatomy and tumor from MRI?\n",
            "ans: Model: Segment-MRI\n",
            "Prompt: Segment left carotid from MRI.\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Segment Clival Recess from video?\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Precise segmentation of clival recess?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging with the surgical frame?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging with surgical scene.\n",
            "pred: Model: Detection\n",
            "Prompt: Which instrument quantities is being used?\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: which instrument quantities is being used?\n",
            "pred: Model: Detection\n",
            "Prompt: Locate instruments in the surgical scene.\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: locate the instruments in the surgical scene.\n",
            "pred: Model: Detection\n",
            "Prompt: Explain the role of the phases in this step?\"\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: explain the role of the phases in this step.\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Segment the region of Left Carotid from video?\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Analyze left carotid?\n",
            "pred: Model: Operation_Notes\n",
            "Prompt: What is the position of the operation notes?\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: what is the position of the operation notes?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Merge the tumor segmentation images with surgical video in real-time?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay tumor segmentation with surgical scene.\n",
            "pred: Model: Detection\n",
            "Prompt: Detect surgical instruments in the video?\n",
            "ans: Model: Detection-Video\n",
            "Prompt: what surgical instruments can be detected in the video?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging and surgical frame?\"\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging with surgical scene.\n",
            "pred: Model: Segmentation_MRI\n",
            "Prompt: Segment anatomy and tumor from MRI?\n",
            "ans: Model: Segment-MRI\n",
            "Prompt: Segment clival recess from MRI.\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging on the surgical video?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging with surgical scene.\n",
            "pred: Model: Detection\n",
            "Prompt: Identify all the instruments present in this frame?\"\n",
            "ans: Model: Detection-Video\n",
            "Prompt: find all the instruments visible in this video frame?\n",
            "pred: Model: Segmentation_MRI, Overlaying\n",
            "Prompt: Segment MRI?|Overlay on surgical scene?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation with surgical scene.\n",
            "pred: Model: Segmentation_MRI, Overlaying, Detection\n",
            "Prompt: Overlay diagnostic MRI on video?|Detect tool positions?\n",
            "ans: Model: Surgical-VQA|Overlaying\n",
            "Prompt: Overlay diagnostic MRI on surgical video?|Detect tool positions?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging with the surgical scene? Identify instruments?\n",
            "ans: Model: Detection|Overlaying\n",
            "Prompt: Overlay preoperative imaging with the surgical scene?|Identify instruments?\n",
            "pred: Model: Detection\n",
            "Prompt: Detect surgical instruments in the video?\n",
            "ans: Model: Detection-Video\n",
            "Prompt: what surgical instruments can be detected in the video?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation and the surgical frame?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation with surgical scene.\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation on surgical video.\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation with surgical scene.\n",
            "pred: Model: Detection\n",
            "Prompt: Analyze the instruments in this phase.\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: analyze the instruments in this phase.\n",
            "pred: Model: Detection, Overlaying\n",
            "Prompt: Detect instruments in video? | Overlay diagnostic MRI on the detected instruments from video?\"\n",
            "ans: Model: Detection|Segmentation_Video\n",
            "Prompt: Detect instruments in video?|Overlay diagnostic diagnostic mri?\n",
            "pred: Model: Detection\n",
            "Prompt: Describe the steps being used?\"\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: describe the steps being used.\n",
            "pred: Model: Phase_Detection\n",
            "Prompt: Analyze the current phase and segment optic protuberances in video?\n",
            "ans: Model: Surgical-VQA|Overlaying\n",
            "Prompt: Analyze the current phase?|Segment optic protuberances in video?\n",
            "pred: Model: Detection\n",
            "Prompt: Identify all instruments visible in this video frame?\n",
            "ans: Model: Detection-Video\n",
            "Prompt: find all the instruments visible in this video frame?\n",
            "pred: Model: Segmentation_MRI\n",
            "Prompt: Precisely segment the tumor from MRI data?\n",
            "ans: Model: Segment-MRI\n",
            "Prompt: Segment tumor from MRI.\n",
            "pred: Model: Overlaying, Segmentation_MRI\n",
            "Prompt: Overlay tumor segmentation with the surgical scene and identify tool positions?\n",
            "ans: Model: Segmentation_Video|Segmentation_MRI\n",
            "Prompt: Overlay tumor segmentation with the surgical scene?|Identify tool positions?\n",
            "pred: Model: Detection\n",
            "Prompt: Detect surgical instruments in the video?\n",
            "ans: Model: Detection-Video\n",
            "Prompt: what surgical instruments can be detected in the video?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Combine preoperative imaging and surgical visuals into an overlay?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay preoperative imaging with surgical scene.\n",
            "pred: Model: Detection, Overlaying\n",
            "Prompt: Detect instruments in video? | Overlay diagnostic tumor segmentation?\"\n",
            "ans: Model: Detection|Segmentation_Video\n",
            "Prompt: Detect instruments in video?|Overlay diagnostic tumor segmentation?\n",
            "pred: Model: Instrument_Position\n",
            "Prompt: Which instrument positions are being used?\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: which instrument positions is being used?\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Perform segmentation of Left Optic Protuberance from video?\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Locate left optic protuberance?\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Segment Right Optic Protuberance in the current frame of video?\"\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Identify right optic protuberance?\n",
            "pred: Model: Detection\n",
            "Prompt: Locate instrument quantities in the surgical scene.\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: locate the instrument quantities in the surgical scene.\n",
            "pred: Model: Segmentation_MRI\n",
            "Prompt: Locate and segment the optic protuberances region in MRI?\n",
            "ans: Model: Segment-MRI\n",
            "Prompt: Segment optic protuberances from MRI.\n",
            "pred: Model: Detection\n",
            "Prompt: Identify the instruments being used?\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: which instruments is being used?\n",
            "pred: Model: Overlaying\n",
            "Prompt: Display an overlay of anatomy segmentation on the surgical field?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay anatomy segmentation with surgical scene.\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Locate and segment Clival Recess from video?\"\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Segment clival recess?\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Precisely segment Left Optic Protuberance from video?\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Detect left optic protuberance?\n",
            "pred: Model: Segmentation_MRI, Overlaying\n",
            "Prompt: Segment tumor margins from MRI?|Overlay on video?\n",
            "ans: Model: Surgical-VQA|Overlaying\n",
            "Prompt: Segment tumor margins from MRI?|Overlay on video?\n",
            "pred: Model: Segmentation_MRI\n",
            "Prompt: Segment clival recess from MRI?\n",
            "ans: Model: Segment-MRI\n",
            "Prompt: Segment clival recess from MRI.\n",
            "pred: Model: Overlaying\n",
            "Prompt: Overlay MRI diagnosis and highlight anatomical structures?\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay diagnosis MRI with surgical scene.\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Segment Clival Recess from video?\"\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Identify clival recess?\n",
            "pred: Model: Segmentation_MRI|Overlaying\n",
            "Prompt: Segment the diagnosis from MRI?|Overlay on the surgical frame?\"\n",
            "ans: Model: Overlaying\n",
            "Prompt: Overlay diagnosis MRI with surgical scene.\n",
            "pred: Model: Segmentation_Video\n",
            "Prompt: Locate and segment Sella from video?\n",
            "ans: Model: Segment-Video\n",
            "Prompt: Segment sella?\n",
            "pred: Model: Detection\n",
            "Prompt: What observation can be made about the steps?\n",
            "ans: Model: Surgical-VQA\n",
            "Prompt: what observation can be made about the steps?\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(all_pred)):\n",
        "    print(\"pred:\", all_pred[i])\n",
        "    print(\"ans:\", all_ans[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cbed0fa6-53f8-448d-891a-1931c5605d6e",
      "metadata": {
        "id": "cbed0fa6-53f8-448d-891a-1931c5605d6e",
        "outputId": "172ab424-162e-4c40-9e5b-752e4c322eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379,
          "referenced_widgets": [
            "ca82631144c94f8d9359af5ae9974929",
            "8826c971196d47f6904114bb6951cbd0",
            "ae22db2bfc8349fa92d4874d4bbe5e25",
            "4ddcc8d262d24fd6b3072a2bc7b02557",
            "7a2cae6602d6424bb7b53cc33b14cccd",
            "6325e0fd68b74c78a943d27c2ec0e6c2",
            "602892a1015a467ea9c308eda7894c7f",
            "b39d7deb2e594dbeb74a4894c904cd47",
            "baf050162c1347ab899ff2a38005223b",
            "062d84cc30bc49618b9a382c176f11eb",
            "d4e45da432954b688ac67d703c7f65fe"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=9236672979bbc344ac59f4c84d836942b7cc641496ec7d56f6c28b036b11b689\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca82631144c94f8d9359af5ae9974929"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 0.7465812230783828, 'rouge2': 0.48334332063518365, 'rougeL': 0.7225223873358213, 'rougeLsum': 0.7413116110396836}\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "rouge_results = rouge.compute(predictions= all_pred, references=all_ans)\n",
        "print(rouge_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a890dd44-b069-4624-869a-9799c8ddc9aa",
      "metadata": {
        "id": "a890dd44-b069-4624-869a-9799c8ddc9aa",
        "outputId": "46e41c08-bffa-478c-b11e-5538087ddde6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2917373394717713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "bleu_score = corpus_bleu(all_ans, all_pred, weights=(1.0, 0.0, 0.0, 0.0))\n",
        "print(bleu_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "81cfd734-fbec-4aac-8f89-50f567a96c48",
      "metadata": {
        "id": "81cfd734-fbec-4aac-8f89-50f567a96c48",
        "outputId": "413bf5b2-6856-42d3-fa26-c5cfe546c1bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.757290762185491\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "m_score=0\n",
        "for line in zip(all_ans, all_pred):\n",
        "    ref = word_tokenize(line[0])\n",
        "    hypo = word_tokenize(line[1])\n",
        "    m_score += meteor_score([ref], hypo)\n",
        "meteors = m_score/len(all_ans)\n",
        "print(meteors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b31786b-2e00-4a3c-a85b-809ce48cfcaa",
      "metadata": {
        "id": "0b31786b-2e00-4a3c-a85b-809ce48cfcaa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6017dd69-1978-417f-93fe-0393b4cc3f74",
      "metadata": {
        "id": "6017dd69-1978-417f-93fe-0393b4cc3f74"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66908c8-03b7-4e61-ab7c-a4fc51cfac25",
      "metadata": {
        "id": "c66908c8-03b7-4e61-ab7c-a4fc51cfac25"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb57e80-8aeb-4dc2-bde4-999d999f1e7c",
      "metadata": {
        "id": "aeb57e80-8aeb-4dc2-bde4-999d999f1e7c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b257eab5f5a540fc8e1a6141deb5dc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6432ea28e1848bfa837507ae143c102",
              "IPY_MODEL_5508dcc897de40d2ad2911981a610c8e",
              "IPY_MODEL_4601df29480f4609b1d3667221c2b782"
            ],
            "layout": "IPY_MODEL_083885a160f74cb8a88524460b14cdc6"
          }
        },
        "d6432ea28e1848bfa837507ae143c102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e033b9cec6c1470caaa20bc30aa530f1",
            "placeholder": "​",
            "style": "IPY_MODEL_bd6c26ba6d4f4198902c88978d03e5aa",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "5508dcc897de40d2ad2911981a610c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d3ae19bb8142d2b434843c298fc86b",
            "max": 437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74198e64efdd4d8c85252b1225246230",
            "value": 437
          }
        },
        "4601df29480f4609b1d3667221c2b782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89c365723a248698bde13eb2488db87",
            "placeholder": "​",
            "style": "IPY_MODEL_4d669d28b0d94a848348cf9e0b10ae5c",
            "value": " 437/437 [00:00&lt;00:00, 25.1kB/s]"
          }
        },
        "083885a160f74cb8a88524460b14cdc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e033b9cec6c1470caaa20bc30aa530f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6c26ba6d4f4198902c88978d03e5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d3ae19bb8142d2b434843c298fc86b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74198e64efdd4d8c85252b1225246230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a89c365723a248698bde13eb2488db87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d669d28b0d94a848348cf9e0b10ae5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a8e527aaabf4921b7aa7e00756d1ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44108ab511934f98ace0deba376de114",
              "IPY_MODEL_b8d610dbe40e4ca993aa267f88b0a0ff",
              "IPY_MODEL_e7dc7c06b3ff4370b115f1f0ba4cf98f"
            ],
            "layout": "IPY_MODEL_c8776c5664e04b6da4674b1d6f2b32f8"
          }
        },
        "44108ab511934f98ace0deba376de114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2467cbb2b34680bc69cca3ef583ef3",
            "placeholder": "​",
            "style": "IPY_MODEL_e913023140314001be99e71afa9b53b0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b8d610dbe40e4ca993aa267f88b0a0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726f30f1cf8c495aa2ce4088d8e15d82",
            "max": 55782,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0149518f1a3f4d8cb19c865f05b68919",
            "value": 55782
          }
        },
        "e7dc7c06b3ff4370b115f1f0ba4cf98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860b6c3d2e9c48e89364238e302edcd9",
            "placeholder": "​",
            "style": "IPY_MODEL_62cf37d220894b9182eb8b75b516b607",
            "value": " 55.8k/55.8k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "c8776c5664e04b6da4674b1d6f2b32f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2467cbb2b34680bc69cca3ef583ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e913023140314001be99e71afa9b53b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726f30f1cf8c495aa2ce4088d8e15d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0149518f1a3f4d8cb19c865f05b68919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "860b6c3d2e9c48e89364238e302edcd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62cf37d220894b9182eb8b75b516b607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7701ec2b0dac41b5bbb539a3995e1741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d882d8188784dbd9991a31955214b9f",
              "IPY_MODEL_29cd72d2b78940fb96be87b82225ea51",
              "IPY_MODEL_8ce1698c0310409589a9123ca32d33c8"
            ],
            "layout": "IPY_MODEL_3b5d915497794237977763634884593e"
          }
        },
        "3d882d8188784dbd9991a31955214b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2afd33b154674527a22f64335046a901",
            "placeholder": "​",
            "style": "IPY_MODEL_6a9f05867e364145a9937beaa6fe9ee1",
            "value": "config.json: 100%"
          }
        },
        "29cd72d2b78940fb96be87b82225ea51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2bd666285404cef88362478de3dcc8c",
            "max": 5068,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af34de6f27704eeab99d71f88ab8b31d",
            "value": 5068
          }
        },
        "8ce1698c0310409589a9123ca32d33c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23920a61e87247cda96c97c960d2c9a8",
            "placeholder": "​",
            "style": "IPY_MODEL_2fd52311eb694801bb79b3174747622d",
            "value": " 5.07k/5.07k [00:00&lt;00:00, 381kB/s]"
          }
        },
        "3b5d915497794237977763634884593e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2afd33b154674527a22f64335046a901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9f05867e364145a9937beaa6fe9ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2bd666285404cef88362478de3dcc8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af34de6f27704eeab99d71f88ab8b31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23920a61e87247cda96c97c960d2c9a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd52311eb694801bb79b3174747622d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9f99a65ca94814a17831eb7efc5586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_243d4d1ca75d4a4895b90612af4abb7c",
              "IPY_MODEL_baaef3ce4d4b49f59b107676fabf0493",
              "IPY_MODEL_c37a1157373a46288d0f6bb6a3255f6e"
            ],
            "layout": "IPY_MODEL_9fdbab9e7f3c4538beec3a0f48efa2cf"
          }
        },
        "243d4d1ca75d4a4895b90612af4abb7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41ad0044bb2645a588ead85cf9a24406",
            "placeholder": "​",
            "style": "IPY_MODEL_c905417875c3457e823cc99d298cf3c8",
            "value": "tokenizer.json: 100%"
          }
        },
        "baaef3ce4d4b49f59b107676fabf0493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae9d411ac30490a956970b51d6c1e37",
            "max": 9085825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a85d5dea72a44148f02bbdc9a7ba6f6",
            "value": 9085825
          }
        },
        "c37a1157373a46288d0f6bb6a3255f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d86dd41bc7343479cad3dc78fed3683",
            "placeholder": "​",
            "style": "IPY_MODEL_42ce59ef2aec447d8363455c6d25d8dd",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 27.0MB/s]"
          }
        },
        "9fdbab9e7f3c4538beec3a0f48efa2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ad0044bb2645a588ead85cf9a24406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c905417875c3457e823cc99d298cf3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cae9d411ac30490a956970b51d6c1e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a85d5dea72a44148f02bbdc9a7ba6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d86dd41bc7343479cad3dc78fed3683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42ce59ef2aec447d8363455c6d25d8dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f2e63bfc89145e890e404a7012c445c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_942e36879ae349fd8ebac633bb9a3a2b",
              "IPY_MODEL_3236b4ad543d40b7a71ee6485bdbc511",
              "IPY_MODEL_36bd4fcb74874a75afbdf1c85540017a"
            ],
            "layout": "IPY_MODEL_14e3bc65e92447ab91072ccc9933b0b3"
          }
        },
        "942e36879ae349fd8ebac633bb9a3a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad14eaa908d4a7a97711540e3cea21a",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce694e4fedd487f8d990132d252978e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3236b4ad543d40b7a71ee6485bdbc511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b65406142b499e8c81958a63f510d5",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fb2ede9531c4dd099380ead6d14b4e3",
            "value": 454
          }
        },
        "36bd4fcb74874a75afbdf1c85540017a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ed65dcb42ef4142b2485ce4ba2219f1",
            "placeholder": "​",
            "style": "IPY_MODEL_607ae9c3e556497e920889e36c96d131",
            "value": " 454/454 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "14e3bc65e92447ab91072ccc9933b0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad14eaa908d4a7a97711540e3cea21a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce694e4fedd487f8d990132d252978e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6b65406142b499e8c81958a63f510d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb2ede9531c4dd099380ead6d14b4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ed65dcb42ef4142b2485ce4ba2219f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607ae9c3e556497e920889e36c96d131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc76413bc788476aa5213474859b4bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_979b4d48a7294c599edeca5147b8878e",
              "IPY_MODEL_603337f24f0e4becb7c21bea97f28b48",
              "IPY_MODEL_85a137be1cf648978be378e0008b113b"
            ],
            "layout": "IPY_MODEL_61a2a8bc993d4b3691ce65dc09f82c67"
          }
        },
        "979b4d48a7294c599edeca5147b8878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba7ee6275a846d3ad979321bc2175d9",
            "placeholder": "​",
            "style": "IPY_MODEL_dcfdb656bdb1488eabc248abfa495558",
            "value": "chat_template.json: 100%"
          }
        },
        "603337f24f0e4becb7c21bea97f28b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0ecf9a9ce0434da2e3996e67c333a5",
            "max": 5089,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7584c5cdaa24a7eb0674f9c422abf2a",
            "value": 5089
          }
        },
        "85a137be1cf648978be378e0008b113b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a54a6d4286465fa8896b0c8374e9d1",
            "placeholder": "​",
            "style": "IPY_MODEL_5e266cd4871f47728e28005cb162c98f",
            "value": " 5.09k/5.09k [00:00&lt;00:00, 360kB/s]"
          }
        },
        "61a2a8bc993d4b3691ce65dc09f82c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba7ee6275a846d3ad979321bc2175d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcfdb656bdb1488eabc248abfa495558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0ecf9a9ce0434da2e3996e67c333a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7584c5cdaa24a7eb0674f9c422abf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60a54a6d4286465fa8896b0c8374e9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e266cd4871f47728e28005cb162c98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "013f0a9b1d264a3ea6973e4974a059cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ae4cf4fdd964f38a1a1da50c078c20a",
              "IPY_MODEL_a1effd358375431e92414c2fb2fc5b33",
              "IPY_MODEL_562a78514010451eaebcd1290db29f15"
            ],
            "layout": "IPY_MODEL_4ccab6936a19405abf838c5160d201c2"
          }
        },
        "6ae4cf4fdd964f38a1a1da50c078c20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d84970f98e4b41ad9b057be8f104c2da",
            "placeholder": "​",
            "style": "IPY_MODEL_8ad00f9d6f4746578d45b4f92d14e913",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "a1effd358375431e92414c2fb2fc5b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1524eb992f4b4334af3679a54adb2886",
            "max": 89446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d0960554886483d8872aeaad7839e0b",
            "value": 89446
          }
        },
        "562a78514010451eaebcd1290db29f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906b9410515348649a8efab5c643a6f9",
            "placeholder": "​",
            "style": "IPY_MODEL_c9b6f745feda4d03af21abd0070ee51d",
            "value": " 89.4k/89.4k [00:00&lt;00:00, 1.40MB/s]"
          }
        },
        "4ccab6936a19405abf838c5160d201c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84970f98e4b41ad9b057be8f104c2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad00f9d6f4746578d45b4f92d14e913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1524eb992f4b4334af3679a54adb2886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0960554886483d8872aeaad7839e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "906b9410515348649a8efab5c643a6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b6f745feda4d03af21abd0070ee51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82f29a686d2b4765acb6c5f40ec0df34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be74bd0dd49f47778d993e137601ba4a",
              "IPY_MODEL_156529890d01435689798a0009803161",
              "IPY_MODEL_ebd62e4c42304d198c24f4ed924c9542"
            ],
            "layout": "IPY_MODEL_bc752736e8c94b2eaab44a932041ccf6"
          }
        },
        "be74bd0dd49f47778d993e137601ba4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2cc7cfc5c854fd18e58684dbe199be7",
            "placeholder": "​",
            "style": "IPY_MODEL_47d428a0fb0946039b2ccbac548ebb49",
            "value": "Downloading shards: 100%"
          }
        },
        "156529890d01435689798a0009803161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bd5bd357134397943408177d832f2c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7f14ee4b3ad4081b78ee15e9ad40147",
            "value": 5
          }
        },
        "ebd62e4c42304d198c24f4ed924c9542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166a0e264daa44219d31ecbdfb067573",
            "placeholder": "​",
            "style": "IPY_MODEL_3901714efe894f17988f9241bbd49aed",
            "value": " 5/5 [08:27&lt;00:00, 88.11s/it]"
          }
        },
        "bc752736e8c94b2eaab44a932041ccf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2cc7cfc5c854fd18e58684dbe199be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d428a0fb0946039b2ccbac548ebb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1bd5bd357134397943408177d832f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f14ee4b3ad4081b78ee15e9ad40147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "166a0e264daa44219d31ecbdfb067573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3901714efe894f17988f9241bbd49aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4429f342e8f64c4eab9f8b30f2e6cf63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4fd2c30c0d84253bc7ff3607b3c09d4",
              "IPY_MODEL_8c5e18361a804401967f2fd24f9672f7",
              "IPY_MODEL_64811cc516684c06844734fd6d1287fc"
            ],
            "layout": "IPY_MODEL_c3e27cc60fea43088c970b56fb3a8587"
          }
        },
        "e4fd2c30c0d84253bc7ff3607b3c09d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33d3635d82074e2a9dab366a6f07dd29",
            "placeholder": "​",
            "style": "IPY_MODEL_fd92fb47a14b46558acee7ee076e8053",
            "value": "model-00001-of-00005.safetensors: 100%"
          }
        },
        "8c5e18361a804401967f2fd24f9672f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94363358229b4ef8b259f8e24a6c9d18",
            "max": 4992622346,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcf8c329878e40039d66a528e5c01925",
            "value": 4992622346
          }
        },
        "64811cc516684c06844734fd6d1287fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d050334b0a846df913c6ce5dedec58a",
            "placeholder": "​",
            "style": "IPY_MODEL_00717e97d6584cc3a9d5ade74dd3b985",
            "value": " 4.99G/4.99G [01:58&lt;00:00, 42.1MB/s]"
          }
        },
        "c3e27cc60fea43088c970b56fb3a8587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d3635d82074e2a9dab366a6f07dd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd92fb47a14b46558acee7ee076e8053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94363358229b4ef8b259f8e24a6c9d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf8c329878e40039d66a528e5c01925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d050334b0a846df913c6ce5dedec58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00717e97d6584cc3a9d5ade74dd3b985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd677af4c1449008c9953ff63f5a9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53023f6973b341bc91de002fd8a59382",
              "IPY_MODEL_6141f69345ef4b0cb1ba467f1103a490",
              "IPY_MODEL_b2482a8a41914603b5f3f74b12ad4768"
            ],
            "layout": "IPY_MODEL_9286c7b03b06496da27c9d282d2bfff4"
          }
        },
        "53023f6973b341bc91de002fd8a59382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_429dec557cdb4a80bcab7a6176418eb9",
            "placeholder": "​",
            "style": "IPY_MODEL_57fcdd66f27d4c6fbf4284e45f89fe5e",
            "value": "model-00002-of-00005.safetensors: 100%"
          }
        },
        "6141f69345ef4b0cb1ba467f1103a490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5875fc1541d647788575f4a7fde87e9e",
            "max": 4966251712,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e92a27da2ba6484fa815068947753cbf",
            "value": 4966251712
          }
        },
        "b2482a8a41914603b5f3f74b12ad4768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4edb5ca7df5742878ef4d714c1439bb2",
            "placeholder": "​",
            "style": "IPY_MODEL_1fc2f0f1f3d74452a4fecc3c1deac23c",
            "value": " 4.97G/4.97G [01:58&lt;00:00, 41.8MB/s]"
          }
        },
        "9286c7b03b06496da27c9d282d2bfff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429dec557cdb4a80bcab7a6176418eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57fcdd66f27d4c6fbf4284e45f89fe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5875fc1541d647788575f4a7fde87e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92a27da2ba6484fa815068947753cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4edb5ca7df5742878ef4d714c1439bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc2f0f1f3d74452a4fecc3c1deac23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd00e40dcb41407eae010cd4b3af7203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_754a82c540c24bed826928735c0c5d2d",
              "IPY_MODEL_c070b4047eec49a2bdaca25ff46cfce6",
              "IPY_MODEL_bd6432b6fdc74217a7e7da1c7010c207"
            ],
            "layout": "IPY_MODEL_f4868893ea424cf1825170141abd2502"
          }
        },
        "754a82c540c24bed826928735c0c5d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08cadc27505e4efbb8c973f374460a6e",
            "placeholder": "​",
            "style": "IPY_MODEL_835c4e33c06c4ea491a17783f033123c",
            "value": "model-00003-of-00005.safetensors: 100%"
          }
        },
        "c070b4047eec49a2bdaca25ff46cfce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39881d1fd0d4b6ca0188449a3a0a119",
            "max": 4915919704,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9338d39ebbbb4b3eaf03cc7e18248e27",
            "value": 4915919704
          }
        },
        "bd6432b6fdc74217a7e7da1c7010c207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e5774452ea6455b99cd70c62e7c63bb",
            "placeholder": "​",
            "style": "IPY_MODEL_ecc26e03a15c4728856ded157d901252",
            "value": " 4.92G/4.92G [01:56&lt;00:00, 42.0MB/s]"
          }
        },
        "f4868893ea424cf1825170141abd2502": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08cadc27505e4efbb8c973f374460a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835c4e33c06c4ea491a17783f033123c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f39881d1fd0d4b6ca0188449a3a0a119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9338d39ebbbb4b3eaf03cc7e18248e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e5774452ea6455b99cd70c62e7c63bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc26e03a15c4728856ded157d901252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "240b71cb3b924d1580316a09a139050e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed2e7273330041199adf85f77f94a659",
              "IPY_MODEL_7cfd0adc72194c2cac64bd57fc2e7a75",
              "IPY_MODEL_9dc3b8161e2640419794b09d4a7791ba"
            ],
            "layout": "IPY_MODEL_d7b13982bc2a41d1a174f4fbcb2e25ea"
          }
        },
        "ed2e7273330041199adf85f77f94a659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8987d98778964c59b418e6cf63aab206",
            "placeholder": "​",
            "style": "IPY_MODEL_ca503b9c005d46398e25aeab5b4bdb30",
            "value": "model-00004-of-00005.safetensors: 100%"
          }
        },
        "7cfd0adc72194c2cac64bd57fc2e7a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3577b37273bb4cd5b54ead66e7c074a4",
            "max": 4999823980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84eb9764084a4f88b769b14055cd381e",
            "value": 4999823980
          }
        },
        "9dc3b8161e2640419794b09d4a7791ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95272298f2b04d45835de2316a73245c",
            "placeholder": "​",
            "style": "IPY_MODEL_4ce0627561764eedbe58a831f0b70a7f",
            "value": " 5.00G/5.00G [01:58&lt;00:00, 42.0MB/s]"
          }
        },
        "d7b13982bc2a41d1a174f4fbcb2e25ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8987d98778964c59b418e6cf63aab206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca503b9c005d46398e25aeab5b4bdb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3577b37273bb4cd5b54ead66e7c074a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84eb9764084a4f88b769b14055cd381e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95272298f2b04d45835de2316a73245c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce0627561764eedbe58a831f0b70a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "630055cda41c4473a8b9406844625889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87eac49948f24486b9c75d672ce5fcb4",
              "IPY_MODEL_c24115a725ab410dac8c1aea319daceb",
              "IPY_MODEL_ab3904ad9eba40faad5f8daf2b878cba"
            ],
            "layout": "IPY_MODEL_6fec99e10b74465da2338eb4873e854f"
          }
        },
        "87eac49948f24486b9c75d672ce5fcb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67aeb20297b47f0990f608f29beee7c",
            "placeholder": "​",
            "style": "IPY_MODEL_51cb613b134941d1989b47e8a629b948",
            "value": "model-00005-of-00005.safetensors: 100%"
          }
        },
        "c24115a725ab410dac8c1aea319daceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_765c332077254178a15bab6fa1a5a343",
            "max": 1465943128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3d9a818191a4333bd542253a676be94",
            "value": 1465943128
          }
        },
        "ab3904ad9eba40faad5f8daf2b878cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2d7958ea77c434784693bf5649d8d57",
            "placeholder": "​",
            "style": "IPY_MODEL_65db0f9366304a4d9536b933d5026841",
            "value": " 1.47G/1.47G [00:34&lt;00:00, 42.7MB/s]"
          }
        },
        "6fec99e10b74465da2338eb4873e854f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67aeb20297b47f0990f608f29beee7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cb613b134941d1989b47e8a629b948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "765c332077254178a15bab6fa1a5a343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d9a818191a4333bd542253a676be94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2d7958ea77c434784693bf5649d8d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65db0f9366304a4d9536b933d5026841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbbd01e12a7f4d8d8711e14d8589e045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b70ff35f31d44c2bbe58f96120d62ea6",
              "IPY_MODEL_cb118f0718f24b6db23a04e2b4571025",
              "IPY_MODEL_f69a00d75cfe4234a820d8e10159700d"
            ],
            "layout": "IPY_MODEL_d85b7e1bff2a4beda7c97681cf901eed"
          }
        },
        "b70ff35f31d44c2bbe58f96120d62ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5728c845e347478cbbf4913b37fcf4a3",
            "placeholder": "​",
            "style": "IPY_MODEL_d72de1ae238842b791c9c33eae2c665f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cb118f0718f24b6db23a04e2b4571025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07e00276353449028143544eafb1fce4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1010c483e2949ec925915e6b23d1cec",
            "value": 5
          }
        },
        "f69a00d75cfe4234a820d8e10159700d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86deb56eca8417ca4f035862a071c9d",
            "placeholder": "​",
            "style": "IPY_MODEL_d0b1b5c85baa4dc0b80e2e1f45aec7f6",
            "value": " 5/5 [01:35&lt;00:00, 16.55s/it]"
          }
        },
        "d85b7e1bff2a4beda7c97681cf901eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5728c845e347478cbbf4913b37fcf4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72de1ae238842b791c9c33eae2c665f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07e00276353449028143544eafb1fce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1010c483e2949ec925915e6b23d1cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d86deb56eca8417ca4f035862a071c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b1b5c85baa4dc0b80e2e1f45aec7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bd228ff43d5446bbcb6d9bcd06bcd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96f4994cda84462b9fbfe5624ad94f79",
              "IPY_MODEL_10311269dbc44f5fb993726c5ddfa26e",
              "IPY_MODEL_eae033ef9032420487cfc300a63f027d"
            ],
            "layout": "IPY_MODEL_83bd8677dfc04645abc5276071fe6b72"
          }
        },
        "96f4994cda84462b9fbfe5624ad94f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b763ad02dbdb47d5a1032a231d6fc94a",
            "placeholder": "​",
            "style": "IPY_MODEL_06ad4cf03d4045558d8164e8a0f3241b",
            "value": "generation_config.json: 100%"
          }
        },
        "10311269dbc44f5fb993726c5ddfa26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a93f430d1da945ef9967afdf3be98411",
            "max": 215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48da9892beb746d4b8dd4b33d4972bee",
            "value": 215
          }
        },
        "eae033ef9032420487cfc300a63f027d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea46395b281c42fcbc7283e0b53eb720",
            "placeholder": "​",
            "style": "IPY_MODEL_60733d96a20247e2bc384e9ab9452a57",
            "value": " 215/215 [00:00&lt;00:00, 9.12kB/s]"
          }
        },
        "83bd8677dfc04645abc5276071fe6b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b763ad02dbdb47d5a1032a231d6fc94a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ad4cf03d4045558d8164e8a0f3241b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a93f430d1da945ef9967afdf3be98411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48da9892beb746d4b8dd4b33d4972bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea46395b281c42fcbc7283e0b53eb720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60733d96a20247e2bc384e9ab9452a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca82631144c94f8d9359af5ae9974929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8826c971196d47f6904114bb6951cbd0",
              "IPY_MODEL_ae22db2bfc8349fa92d4874d4bbe5e25",
              "IPY_MODEL_4ddcc8d262d24fd6b3072a2bc7b02557"
            ],
            "layout": "IPY_MODEL_7a2cae6602d6424bb7b53cc33b14cccd"
          }
        },
        "8826c971196d47f6904114bb6951cbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6325e0fd68b74c78a943d27c2ec0e6c2",
            "placeholder": "​",
            "style": "IPY_MODEL_602892a1015a467ea9c308eda7894c7f",
            "value": "Downloading builder script: 100%"
          }
        },
        "ae22db2bfc8349fa92d4874d4bbe5e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39d7deb2e594dbeb74a4894c904cd47",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_baf050162c1347ab899ff2a38005223b",
            "value": 6270
          }
        },
        "4ddcc8d262d24fd6b3072a2bc7b02557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_062d84cc30bc49618b9a382c176f11eb",
            "placeholder": "​",
            "style": "IPY_MODEL_d4e45da432954b688ac67d703c7f65fe",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 331kB/s]"
          }
        },
        "7a2cae6602d6424bb7b53cc33b14cccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6325e0fd68b74c78a943d27c2ec0e6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602892a1015a467ea9c308eda7894c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39d7deb2e594dbeb74a4894c904cd47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf050162c1347ab899ff2a38005223b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "062d84cc30bc49618b9a382c176f11eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e45da432954b688ac67d703c7f65fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}